use super::{ChunkMetadata, FileStore, IndexManifest};
use crate::vector_db::chunking::TextChunker;
use crate::vector_db::core::{Chunk, Result, VectorDbConfig, VectorDbError};
use crate::vector_db::embedding::Embedder;
use crate::vector_db::utils::{blake3_hash_bytes, collect_source_files};
use parking_lot::RwLock;
use std::path::{Path, PathBuf};
use std::sync::Arc;

#[derive(Debug, Clone, Copy)]
pub struct IndexFileOutcome {
    pub indexed_chunks: usize,
}

pub struct IndexManager {
    pub(crate) store: Arc<FileStore>,
    pub(crate) manifest: Arc<RwLock<IndexManifest>>,
    pub(crate) config: VectorDbConfig,
}

impl IndexManager {
    pub fn new(project_root: &Path, config: VectorDbConfig) -> Result<Self> {
        let store = Arc::new(FileStore::new(project_root)?);
        store.initialize()?;

        let manifest_path = store.root_path().join("manifest.json");
        let manifest = if manifest_path.exists() {
            IndexManifest::load(&manifest_path)?
        } else {
            IndexManifest::new(
                config.embedding.model_name.clone(),
                config.embedding.dimension,
            )
        };

        Ok(Self {
            store,
            manifest: Arc::new(RwLock::new(manifest)),
            config,
        })
    }

    fn manifest_path(&self) -> PathBuf {
        self.store.root_path().join("manifest.json")
    }

    fn save_manifest(&self) -> Result<()> {
        let manifest = self.manifest.read().clone();
        manifest.save(&self.manifest_path())
    }

    pub async fn index_file_with(&self, file_path: &Path, embedder: &dyn Embedder) -> Result<()> {
        let _ = self
            .index_file_with_progress(file_path, embedder, |_done, _total| {})
            .await?;
        Ok(())
    }

    pub async fn index_file_with_progress<F>(
        &self,
        file_path: &Path,
        embedder: &dyn Embedder,
        mut on_progress: F,
    ) -> Result<IndexFileOutcome>
    where
        F: FnMut(usize, usize) + Send,
    {
        // 0. Limit: size
        let meta = std::fs::metadata(file_path).map_err(VectorDbError::Io)?;
        if meta.len() > self.config.max_file_size {
            return Ok(IndexFileOutcome { indexed_chunks: 0 }); // Skip oversized files
        }

        // 1. Read content
        let content = match std::fs::read(file_path) {
            Ok(bytes) => match String::from_utf8(bytes) {
                Ok(s) => s,
                Err(_) => return Ok(IndexFileOutcome { indexed_chunks: 0 }), // Skip non-UTF-8 files
            },
            Err(e) => return Err(VectorDbError::Io(e)),
        };
        let file_hash = blake3_hash_bytes(content.as_bytes());
        let _language = crate::vector_db::core::Language::from_path(file_path);
        let last_modified = meta
            .modified()
            .ok()
            .and_then(|t| t.duration_since(std::time::UNIX_EPOCH).ok())
            .map(|d| d.as_secs())
            .unwrap_or(0);

        // 2. Clean old chunks (if they exist)
        {
            let guard = self.manifest.read();
            let existing_ids: Vec<_> = guard
                .get_file_chunks(file_path)
                .into_iter()
                .map(|(id, _)| id)
                .collect();
            drop(guard);
            if !existing_ids.is_empty() {
                // Delete vector file for this file
                let _ = self.store.delete_file_vectors(file_path);
                let mut manifest = self.manifest.write();
                for chunk_id in existing_ids {
                    manifest.remove_chunk(&chunk_id);
                }
                manifest.remove_file(file_path);
            }
        }

        // 3. Chunking
        let chunker = TextChunker::new(self.config.embedding.chunk_size);
        let chunks: Vec<Chunk> = chunker.chunk(&content, file_path)?;

        if chunks.is_empty() {
            return Ok(IndexFileOutcome { indexed_chunks: 0 });
        }

        // 4. Generate embeddings (batch + progress)
        const EMBED_BATCH_SIZE: usize = 64;
        let total_chunks = chunks.len();
        let mut embeddings: Vec<Vec<f32>> = Vec::with_capacity(total_chunks);
        let mut done_chunks = 0usize;
        on_progress(0, total_chunks);

        while done_chunks < total_chunks {
            let end = (done_chunks + EMBED_BATCH_SIZE).min(total_chunks);
            let texts: Vec<&str> = chunks[done_chunks..end]
                .iter()
                .map(|c| c.content.as_str())
                .collect();

            let mut batch = embedder.embed(&texts).await?;
            if batch.is_empty() {
                return Err(VectorDbError::Embedding("No embeddings returned".into()));
            }

            let actual_dim = batch[0].len();
            if actual_dim != self.config.embedding.dimension {
                tracing::error!(
                    "Vector dimension mismatch: expected {}, actual {}. Please set the correct dimension in model configuration.",
                    self.config.embedding.dimension,
                    actual_dim
                );
                return Err(VectorDbError::InvalidDimension {
                    expected: self.config.embedding.dimension,
                    actual: actual_dim,
                });
            }

            embeddings.append(&mut batch);
            done_chunks = embeddings.len();
            on_progress(done_chunks, total_chunks);
        }

        // 5. Write index and manifest
        let mut file_vectors: Vec<(crate::vector_db::core::ChunkId, Vec<f32>)> =
            Vec::with_capacity(total_chunks);
        {
            let mut manifest = self.manifest.write();
            manifest.add_file(file_path.to_path_buf(), file_hash);
            for (chunk, vecf) in chunks.iter().zip(embeddings.into_iter()) {
                let chunk_hash = blake3_hash_bytes(chunk.content.as_bytes());
                let metadata = ChunkMetadata {
                    file_path: file_path.to_path_buf(),
                    span: chunk.span.clone(),
                    chunk_type: chunk.chunk_type.clone(),
                    hash: chunk_hash,
                };
                // Collect vector data
                file_vectors.push((chunk.id, vecf));
                // add to manifest
                manifest.add_chunk(chunk.id, metadata);
            }
        }

        // Save all vectors for this file at once
        self.store.save_file_vectors(file_path, &file_vectors)?;

        // 6. Save file metadata
        let file_meta = crate::vector_db::core::FileMetadata::new(
            file_path.to_path_buf(),
            blake3_hash_bytes(content.as_bytes()),
            last_modified,
            meta.len(),
        );
        self.store.save_file_metadata(&file_meta)?;

        // 7. Save manifest
        self.save_manifest()?;

        Ok(IndexFileOutcome {
            indexed_chunks: total_chunks,
        })
    }

    pub async fn index_files_with(
        &self,
        file_paths: &[PathBuf],
        embedder: &dyn Embedder,
    ) -> Result<()> {
        use futures::stream::{self, StreamExt};

        // Collect all files that need indexing
        let mut files_to_index = Vec::new();
        for p in file_paths {
            if p.is_file() {
                files_to_index.push(p.clone());
            } else if p.is_dir() {
                let files = collect_source_files(p, self.config.max_file_size);
                files_to_index.extend(files);
            }
        }

        // Parallel indexing (up to 4 concurrent tasks)
        let concurrency = 4;
        let results: Vec<Result<()>> = stream::iter(files_to_index)
            .map(|file_path| async move { self.index_file_with(&file_path, embedder).await })
            .buffer_unordered(concurrency)
            .collect()
            .await;

        // Check for errors
        for result in results {
            result?;
        }

        Ok(())
    }

    pub async fn update_index(&self, file_path: &Path, embedder: &dyn Embedder) -> Result<()> {
        self.index_file_with(file_path, embedder).await
    }

    pub fn remove_file(&self, file_path: &Path) -> Result<()> {
        // Delete vector file for this file
        let _ = self.store.delete_file_vectors(file_path);

        let mut manifest = self.manifest.write();
        let chunk_ids: Vec<_> = manifest
            .get_file_chunks(file_path)
            .into_iter()
            .map(|(id, _)| id)
            .collect();
        for id in chunk_ids {
            manifest.remove_chunk(&id);
        }
        manifest.remove_file(file_path);
        drop(manifest);
        self.save_manifest()?;
        Ok(())
    }

    pub async fn rebuild(&self, root: &Path, embedder: &dyn Embedder) -> Result<()> {
        // Reset manifest
        {
            let mut manifest = self.manifest.write();
            *manifest = IndexManifest::new(
                self.config.embedding.model_name.clone(),
                self.config.embedding.dimension,
            );
        }
        self.save_manifest()?;

        let files = collect_source_files(root, self.config.max_file_size);
        self.index_files_with(&files, embedder).await
    }

    pub fn get_status(&self) -> IndexStatus {
        let manifest = self.manifest.read();
        IndexStatus {
            total_files: manifest.files.len(),
            total_chunks: manifest.chunks.len(),
            embedding_model: manifest.embedding_model.clone(),
            vector_dimension: manifest.vector_dimension,
            size_bytes: 0,
        }
    }

    pub fn get_status_with_size_bytes(&self) -> IndexStatus {
        let mut status = self.get_status();
        match self.store.disk_usage_bytes() {
            Ok(bytes) => status.size_bytes = bytes,
            Err(e) => {
                tracing::warn!("Failed to get index disk usage: {}", e);
            }
        }
        status
    }

    /// Get all chunk IDs
    pub fn get_chunk_ids(&self) -> Vec<crate::vector_db::core::ChunkId> {
        let manifest = self.manifest.read();
        manifest.chunks.keys().cloned().collect()
    }

    /// Get all chunk metadata
    pub fn get_all_chunk_metadata(&self) -> Vec<(crate::vector_db::core::ChunkId, ChunkMetadata)> {
        let manifest = self.manifest.read();
        manifest
            .chunks
            .iter()
            .map(|(id, meta)| (*id, meta.clone()))
            .collect()
    }

    /// Get FileStore reference
    pub fn store(&self) -> &FileStore {
        &self.store
    }
}

#[derive(Debug, serde::Serialize)]
#[serde(rename_all = "camelCase")]
pub struct IndexStatus {
    pub total_files: usize,
    pub total_chunks: usize,
    pub embedding_model: String,
    pub vector_dimension: usize,
    pub size_bytes: u64,
}
